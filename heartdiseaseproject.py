# -*- coding: utf-8 -*-
"""HeartDiseaseProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/adz-21/ML-Projects/blob/main/HeartDiseaseProject.ipynb

Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worldwide. Four out of 5CVD deaths are due to heart attacks and strokes, and one-third of these deaths occur prematurely in people under 70 years of age. Heart failure is a common event caused by CVDs and this dataset contains 11 features that can be used to predict a possible heart disease.

People with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need early detection and management wherein a machine learning model can be of great help.
"""

'''
https://www.kaggle.com/datasets/ritwikb3/heart-disease-cleveland
The dataset is the Cleveland Heart Disease dataset taken from the UCI repository.
The dataset consists of 303 individuals' data.
There are 14 columns in the dataset (which have been extracted from a larger set of 75).
No missing values.
The classification task is to predict whether an individual is suffering from heart disease or not. (0: absence, 1: presence) '''

"""Attribute Information

1. Age: Patients Age in years (Numeric)

2. Sex: Gender (Male : 1; Female : 0) (Nominal)

3. cp: Type of chest pain experienced by patient. This term categorized into 4 category.
[ 0 typical angina, 1 atypical angina, 2 non- anginal pain, 3 asymptomatic (Nominal) ]

4. trestbps: patient's level of blood pressure at resting mode in mm/HG (Numerical)

5. chol: Serum cholesterol in mg/dl (Numeric)

6. fbs: Blood sugar levels on fasting > 120 mg/dl represents as 1 in case of true and 0 as false (Nominal)

7. restecg: Result of electrocardiogram while at rest are represented in 3 distinct values
0 : Normal
1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)
2: showing probable or definite left ventricular hypertrophyby Estes' criteria (Nominal)

8. thalach: Maximum heart rate achieved (Numeric)

9. exang: Angina induced by exercise 0 depicting NO 1 depicting Yes (Nominal)

10. oldpeak: Exercise induced ST-depression in relative with the state of rest (Numeric)

11. slope: ST segment measured in terms of slope during peak exercise
0: up sloping; 1: flat; 2: down sloping(Nominal)

12. ca: The number of major vessels (0 â€“ 3)(nominal)

13. thal: A blood disorder called thalassemia
0: NULL 1: normal blood flow 2: fixed defect (no blood flow in some part of the heart) 3: reversible defect (a blood flow is observed but it is not normal(nominal)

14. target: It is the target variable which we have to predict 1 means patient is suffering from heart disease and 0 means patient is normal.

***Importing Dependencies***


---
"""

import numpy as np  # Useful for making arrays
import pandas as pd  # To use DataFrames ie. structured tables
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import pickle

"""***Data Collection & Processing***"""

# Loading our csv file data into a Pandas DataFrame
heart_data = pd.read_csv('Heart_disease_cleveland_new.csv')

heart_data

heart_data.head()

heart_data.tail()

heart_data.shape

heart_data.info()

# Checking for missing values
heart_data.isnull()

heart_data.isnull().sum()

# Statistical info about the data
heart_data.describe()

heart_data['target'].value_counts()

"""[1: heart disease, 0: Normal]

***Removing the target column from our dataset & storing it separately***


---
"""

X = heart_data.drop(columns = 'target', axis = 1)  # axis = 1 for column, axis = 0 for row
Y = heart_data['target']

print(Y)

print(X)

"""**Splitting the data into training & testing data**

---

"""

X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.2, stratify= Y)

print(X.shape, X_train.shape, X_test.shape)

"""`**Model Training **`

---
We're using a Logistic Regression Model cause its very useful for binary classification


"""

model = LogisticRegression()

# training the model :
model.fit(X_train,Y_train)

"""***Model Evaluation + Accuracy Score***

---




"""

# finding the accuracy on training data :
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction,Y_train)

print("Accuracy of training data : ", training_data_accuracy)

# finding the accuracy of testing data
X_test_prediction = model.predict(X_test)
testing_data_accuracy = accuracy_score(X_test_prediction, Y_test)

print("Accuracy of testing data : ",testing_data_accuracy)

"""***Building A Predictive System***

---



"""

input = (41,0,1,130,204,0,0,172,0,1.4,2,0,2)
#  (41,0,1,130,204,0,0,172,0,1.4,2,0,2) -> 0 & (66,0,3,150,226,0,1,114,0,2.6,0,0,2) -- > should be 1
# (57,1,0,150,276,0,0,112,1,0.6,1,1,1) -->  should be 0
#converting the input data to a numpy array
input_array = np.asarray(input)

#reshaping the numpy array as we are only considering one instance (ie. 1 input value)
final_input = input_array.reshape(1,-1)

prediction = model.predict(final_input)

print(prediction)

if(prediction == 0):
  print("The person does not have a heart disease")
else:
  print("The person has a heart disease")

#Save the trained model as a .pkl file
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)